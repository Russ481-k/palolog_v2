services:
  postgres:
    image: postgres:16.1
    ports:
      - '${DOCKER_DATABASE_PORT:-5432}:5432'
    environment:
      POSTGRES_DB: $DOCKER_DATABASE_NAME
      POSTGRES_USER: $DOCKER_DATABASE_USERNAME
      POSTGRES_PASSWORD: $DOCKER_DATABASE_PASSWORD
    deploy:
      resources:
        limits:
          cpus: '8'
          memory: '24G'
        reservations:
          cpus: '6'
          memory: '16G'
    command:
      - 'postgres'
      - '-c'
      - 'max_connections=2000'
      - '-c'
      - 'shared_buffers=6GB'
      - '-c'
      - 'effective_cache_size=16GB'
      - '-c'
      - 'maintenance_work_mem=1GB'
      - '-c'
      - 'work_mem=32MB'
      - '-c'
      - 'wal_buffers=16MB'
      - '-c'
      - 'random_page_cost=1.1'
      - '-c'
      - 'effective_io_concurrency=200'
      - '-c'
      - 'checkpoint_completion_target=0.9'
      - '-c'
      - 'synchronous_commit=off'
      - '-c'
      - 'max_wal_size=4GB'
      - '-c'
      - 'min_wal_size=2GB'
      - '-c'
      - 'autovacuum_max_workers=4'
    ulimits:
      memlock:
        soft: -1
        hard: -1
      nofile:
        soft: 65536
        hard: 65536
    shm_size: '4gb'

  opensearch:
    image: opensearchproject/opensearch:1.2.0
    container_name: opensearch
    networks:
      - entasys
    ports:
      - '9200:9200'
      - '9600:9600'
    environment:
      - discovery.type=single-node
      - 'OPENSEARCH_JAVA_OPTS=-Xms42g -Xmx42g'
      - TZ=Asia/Seoul
      - 'search.max_open_scroll_context=2000'
      - 'indices.memory.index_buffer_size=20%'
      - 'indices.queries.cache.size=15%'
      - 'thread_pool.write.queue_size=2000'
      - 'thread_pool.search.queue_size=2000'
      - 'indices.fielddata.cache.size=25%'
      - 'indices.recovery.max_bytes_per_sec=200mb'
    deploy:
      resources:
        limits:
          cpus: '12'
          memory: '50G'
        reservations:
          cpus: '8'
          memory: '28G'
    ulimits:
      memlock:
        soft: -1
        hard: -1
      nofile:
        soft: 65536
        hard: 65536
    healthcheck:
      test: ['CMD', 'curl', '-s', '-k', 'https://localhost:9200']
      interval: 30s
      timeout: 10s
      retries: 3
    shm_size: '2gb'

  logstash:
    image: opensearchproject/logstash-oss-with-opensearch-output-plugin:7.16.2
    container_name: logstash
    networks:
      - entasys
    ports:
      - '514:514/udp'
    environment:
      LS_JAVA_OPTS: '-Xms32g -Xmx32g'
      pipeline.batch.size: '100000'
      pipeline.workers: '48' # CPU 코어 수에 따라 조정
      pipeline.batch.delay: '3'
      pipeline.io_threads: '24' # 증가
      pipeline.ordered: 'false'
      pipeline.unsafe_shutdown: 'true'
      pipeline.ecs_compatibility: disabled
      queue.type: memory
      queue.max_bytes: '60gb' # 감소
      queue.checkpoint.writes: '100000' # 감소
      queue.checkpoint.acks: '100000' # 감소
      queue.checkpoint.interval: '1000'
      queue.page_capacity: '1gb' # 감소
      queue.max_pages: 16 # 감소
      queue.max_events: '100000' # int 범위 내로 조정
      queue.drain: 'true'
      TZ: Asia/Seoul
    deploy:
      resources:
        limits:
          cpus: '20' # 32코어의 75%
          memory: '60G' # 전체 메모리의 ~64%
        reservations:
          cpus: '10'
          memory: '24G'
    volumes:
      - ./logstash/pipeline:/usr/share/logstash/pipeline
    command: logstash -f /usr/share/logstash/pipeline/logstash.conf --config.reload.automatic
    ulimits:
      memlock:
        soft: -1
        hard: -1
      nofile:
        soft: 65536
        hard: 65536
      nproc:
        soft: 65535
        hard: 65535
    shm_size: '4gb'

networks:
  entasys:
    driver: bridge
